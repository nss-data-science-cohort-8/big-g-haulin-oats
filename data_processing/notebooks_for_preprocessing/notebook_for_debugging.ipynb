{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1792e304",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irela\\AppData\\Local\\Temp\\ipykernel_30744\\2734334264.py:6: DtypeWarning: Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  faults = pd.read_csv(\"../../data/J1939Faults.csv\")\n"
     ]
    }
   ],
   "source": [
    "# Import statements\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read in data\n",
    "faults = pd.read_csv(\"../../data/J1939Faults.csv\")\n",
    "diagnostics = pd.read_csv(\"../../data/VehicleDiagnosticOnboardData.csv\").pivot(index='FaultId', columns='Name', values='Value') # Immediately pivot diagnostic data on FaultId to then be merged\n",
    "faults_and_diagnostics = faults.merge(diagnostics, how='left', left_on='RecordID', right_on='FaultId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f479abc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1187335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irela\\AppData\\Local\\Temp\\ipykernel_30744\\2179150424.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['DistanceTo' + loc] = np.sqrt((df['Latitude'] - coords[0])**2 + (df['Longitude'] - coords[1])**2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1051146\n"
     ]
    }
   ],
   "source": [
    "def remove_service_locations(df, radius=.05):\n",
    "    \"\"\"\n",
    "    Remove data points that are near service locations.\n",
    "    \"\"\"\n",
    "    # Define service locations\n",
    "    service_locations = {\n",
    "        'Location1': (36.0666667, -86.4347222), \n",
    "        'Location2': (35.5883333, -86.4438888), \n",
    "        'Location3': (36.1950, -83.174722) \n",
    "    }\n",
    "\n",
    "    # Calculate distance to each service location and filter out points within a certain radius (e.g., 5 km)\n",
    "    for loc, coords in service_locations.items():\n",
    "        df['DistanceTo' + loc] = np.sqrt((df['Latitude'] - coords[0])**2 + (df['Longitude'] - coords[1])**2)\n",
    "        df = df[df['DistanceTo' + loc] > radius]  # Filter out points within 5 km (radius)\n",
    "\n",
    "    return df\n",
    "    \n",
    "print(len(faults_and_diagnostics)) # Check the number of records in the merged dataframe\n",
    "print(len(remove_service_locations(faults_and_diagnostics))) # Check the number of records after removing service locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f092d561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [RecordID, ESS_Id, EventTimeStamp, eventDescription, actionDescription, ecuSoftwareVersion, ecuSerialNumber, ecuModel, ecuMake, ecuSource, spn, fmi, active, activeTransitionCount, faultValue, EquipmentID, MCTNumber, Latitude, Longitude, LocationTimeStamp, AcceleratorPedal, BarometricPressure, CruiseControlActive, CruiseControlSetSpeed, DistanceLtd, EngineCoolantTemperature, EngineLoad, EngineOilPressure, EngineOilTemperature, EngineRpm, EngineTimeLtd, FuelLevel, FuelLtd, FuelRate, FuelTemperature, IgnStatus, IntakeManifoldTemperature, LampStatus, ParkingBrake, ServiceDistance, Speed, SwitchedBatteryVoltage, Throttle, TurboBoostPressure]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "print(faults_and_diagnostics[faults_and_diagnostics['EngineTimeLtd'] == np.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85b478a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_cols(df):\n",
    "    \"\"\"\n",
    "    Create target columns for the dataset.\n",
    "    \"\"\"\n",
    "    # Create target column for Full Derate\n",
    "    df['FullDerate'] = (df['spn'] == 5246).astype('int8')\n",
    "    # Order data by truck (EquipmentID) and time\n",
    "    df = df.sort_values(['EquipmentID', 'EventTimeStamp'])\n",
    "    # Ensure time is datetime\n",
    "    df['EventTimeStamp'] = pd.to_datetime(df['EventTimeStamp'])\n",
    "\n",
    "    # Create target column for Derate in next two hours\n",
    "    df['NextDerateTime'] = df.where(df['FullDerate'] == 1)['EventTimeStamp']\n",
    "    df['NextDerateTime'] = df.groupby('EquipmentID')['NextDerateTime'].transform('bfill')\n",
    "    df['HoursUntilNextDerate'] = (df['NextDerateTime'] - df['EventTimeStamp']).dt.total_seconds() / 3600.0\n",
    "    df['DerateInNextTwoHours'] = np.where(df['HoursUntilNextDerate'] <= 2, 1, 0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06e92ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert diagnostic columns to appropriate dtypes\n",
    "for col, dtype in {\n",
    "    \"AcceleratorPedal\":\"float16\",\n",
    "    \"BarometricPressure\":\"float16\",\n",
    "    \"CruiseControlActive\":\"bool\",\n",
    "    \"CruiseControlSetSpeed\":\"float16\",\n",
    "    \"DistanceLtd\":\"float16\",\n",
    "    \"EngineCoolantTemperature\":\"float16\",\n",
    "    \"EngineLoad\":\"float16\",\n",
    "    \"EngineOilPressure\":\"float16\",\n",
    "    \"EngineOilTemperature\":\"float16\",\n",
    "    \"EngineRpm\":\"float16\",\n",
    "    \"EngineTimeLtd\":\"float16\",\n",
    "    \"FuelLevel\":\"float16\",\n",
    "    \"FuelLtd\":\"float32\",\n",
    "    \"FuelRate\":\"float16\",\n",
    "    \"FuelTemperature\":\"float16\",\n",
    "    \"IgnStatus\":\"bool\",\n",
    "    \"IntakeManifoldTemperature\":\"float16\",\n",
    "    \"ParkingBrake\":\"bool\",\n",
    "    \"Speed\":\"float16\",\n",
    "    \"SwitchedBatteryVoltage\":\"float16\",\n",
    "    \"Throttle\":\"float16\",\n",
    "    \"TurboBoostPressure\":\"float16\",\n",
    "    \"eventDescription\":\"str\",\n",
    "    \"EquipmentID\":\"str\"\n",
    "}.items():\n",
    "    if dtype == 'bool':\n",
    "        faults_and_diagnostics[col] = faults_and_diagnostics[col].astype('bool')\n",
    "    else:\n",
    "        faults_and_diagnostics[col] = pd.to_numeric(faults_and_diagnostics[col], errors='coerce').replace([np.inf, -np.inf], np.nan)\n",
    "        #faults_and_diagnostics[col] = faults_and_diagnostics[col].replace([-np.inf, np.inf], np.nan) # Handle infinity values\n",
    "        #faults_and_diagnostics[col] = faults_and_diagnostics[col].astype(dtype, copy=False) # Need to do this because certain numeric columns need to be coerced\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ff08553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [RecordID, ESS_Id, EventTimeStamp, eventDescription, actionDescription, ecuSoftwareVersion, ecuSerialNumber, ecuModel, ecuMake, ecuSource, spn, fmi, active, activeTransitionCount, faultValue, EquipmentID, MCTNumber, Latitude, Longitude, LocationTimeStamp, AcceleratorPedal, BarometricPressure, CruiseControlActive, CruiseControlSetSpeed, DistanceLtd, EngineCoolantTemperature, EngineLoad, EngineOilPressure, EngineOilTemperature, EngineRpm, EngineTimeLtd, FuelLevel, FuelLtd, FuelRate, FuelTemperature, IgnStatus, IntakeManifoldTemperature, LampStatus, ParkingBrake, ServiceDistance, Speed, SwitchedBatteryVoltage, Throttle, TurboBoostPressure]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 44 columns]\n"
     ]
    }
   ],
   "source": [
    "print(faults_and_diagnostics[faults_and_diagnostics['EngineTimeLtd'] == np.inf])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0942714",
   "metadata": {},
   "outputs": [],
   "source": [
    "faults_and_diagnostics = faults_and_diagnostics[faults_and_diagnostics['EngineTimeLtd'] != np.inf]\n",
    "# fix this by removing inf values from EngineTimeLtd column\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdcc95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# throw out anything after a derate for a short amount of time\n",
    "\n",
    "def ffill_nans(df): # alternatively try interpolation, moving averages, KNeighbors\n",
    "    \"\"\"\n",
    "    Forward fill values for each EquipmentID group, resetting after each FullDerate == 1.\n",
    "    \"\"\"\n",
    "    def fill_group(group):\n",
    "        group = group.sort_values('EventTimeStamp')\n",
    "        segment = group['FullDerate'].eq(1).cumsum() # Create segments based on FullDerate == 1\n",
    "        return group.groupby(segment).ffill()\n",
    "\n",
    "    return df.groupby('EquipmentID', group_keys=False).apply(fill_group)\n",
    "\n",
    "# Separate training and testing data based on before and after 2019-01-01\n",
    "faults_and_diagnostics_train = ffill_nans(create_target_cols(faults_and_diagnostics[faults_and_diagnostics['EventTimeStamp']<'2019-01-01']))\n",
    "faults_and_diagnostics_test = ffill_nans(create_target_cols(faults_and_diagnostics[(faults_and_diagnostics['EventTimeStamp']>='2019-01-01') & (faults_and_diagnostics['EventTimeStamp']<='2024-01-01')]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74640a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xy_train_test_split(feature_cols, target_col):\n",
    "    X_train = faults_and_diagnostics_train[feature_cols]\n",
    "    X_test = faults_and_diagnostics_test[feature_cols]\n",
    "    y_train = faults_and_diagnostics_train[target_col]\n",
    "    y_test = faults_and_diagnostics_test[target_col]\n",
    "\n",
    "    # create train and test dataframes\n",
    "    train_df = pd.concat([y_train, X_train], axis=1).rename(columns={target_col: 'target'})\n",
    "    test_df = pd.concat([y_test, X_test], axis=1).rename(columns={target_col: 'target'})\n",
    "\n",
    "    return train_df, test_df\n",
    "\n",
    "def save_to_csv(train_df, test_df, file_name):\n",
    "    \"\"\"\n",
    "    Save the train and test dataframes to CSV files.\n",
    "    \"\"\"\n",
    "    train_file_path = f\"../preprocessed_data/{file_name}_train.csv\"\n",
    "    test_file_path = f\"../preprocessed_data/{file_name}_test.csv\"\n",
    "    \n",
    "    train_df.to_csv(train_file_path, index=False)\n",
    "    test_df.to_csv(test_file_path, index=False)\n",
    "\n",
    "    print(f\"Train and test dataframes saved to {train_file_path} and {test_file_path}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
